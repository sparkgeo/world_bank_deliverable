{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import rioxarray as rioxr\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from skimage import morphology\n",
    "from skimage.measure import label\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths and read in files for subsequent processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main input filepath. All other files and folders should be nested under this one (aside from the road geom file specified below)\n",
    "inpath = Path(\"../data/processed/outputs_BeitBridge_2022-01-01_to_2023-03-27\")\n",
    "\n",
    "#Geometry file for clipping tdi outputs\n",
    "road_geom_file = \"../data/processed/beitbridge_road_mask_v2.gpkg\"\n",
    "\n",
    "img_path = inpath.joinpath(\"Beitbridge_PlanetScope\") #Subfolder containing images downloaded from skywatch api\n",
    "\n",
    "outpath_aligned = inpath.joinpath(\"Processed_Images\") #Output path for co-aligned images\n",
    "outpath_aligned.mkdir(exist_ok=True)\n",
    "\n",
    "outpath_workdir = inpath.joinpath(\"TDI_Outputs\") #Output directory for TDI file outputs\n",
    "outpath_workdir.mkdir(exist_ok=True)\n",
    "\n",
    "img_df_csv = inpath.joinpath(\"search_df_2022-01-01_to_2023-03-27_filtered.csv\") #CSV file generated from dataframe created in the skywatch api notebook\n",
    "img_df = pd.read_csv(img_df_csv)\n",
    "img_df.drop(columns=['Unnamed: 0'], inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Align images\n",
    "This section of the notebook is to take the PlanetScope images downloaded using the skywatch api notebook and resample them to a common pixel grid.\n",
    "Note: this step should only need to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up a base image to resample everything to match. It selects the first image with 100% AOI coverage to use as the base image\n",
    "base_imgname = img_df.loc[img_df[\"aoi_coverage\"] == 100].iloc[0][\"product_name\"]\n",
    "base_img_file = img_path.joinpath(base_imgname, f\"{base_imgname}_analytic.tif\")\n",
    "base_img = rio.open(base_img_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_image(base_img, warp_imgname, out_name):\n",
    "    \"\"\"\n",
    "    Function to resample an image to match the base image\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    base_img: rasterio dataset\n",
    "        base image to be aligned to\n",
    "    warp_imgname: pathlib Path\n",
    "        path to the image to be resampled.\n",
    "    out_name: pathlib Path\n",
    "        output path for resampled image\n",
    "    \"\"\"\n",
    "    \n",
    "    srs = base_img.crs.to_string()\n",
    "    pixelsize_x, pixelsize_y = base_img.res\n",
    "    bbox = base_img.bounds\n",
    "\n",
    "    #First step: create temp file using gdalwarp which resamples the target image to match the base image\n",
    "    cmd = f\"gdalwarp -t_srs {srs} -tap -tr {pixelsize_x} {pixelsize_y} -r near -te {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]} -te_srs {srs} -of vrt {warp_imgname} {out_name}.vrt -overwrite\"\n",
    "    subprocess.check_output(cmd, shell=True)\n",
    "\n",
    "    #Second step: use gdal_translate to compress the temp file into the final output\n",
    "    cmd2 = f\"gdal_translate -co compress=LZW {out_name}.vrt {out_name}.tif\"\n",
    "    subprocess.check_output(cmd2, shell=True)\n",
    "\n",
    "#Iterate through all the images in the img_df dataframe and resample to match the base image\n",
    "for index, row in img_df.iterrows():\n",
    "    img_name = row[\"product_name\"]    \n",
    "    img_file = img_path.joinpath(img_name, f\"{img_name}_analytic.tif\")\n",
    "    img_processedname = outpath_aligned.joinpath(f\"{img_name}_aligned\")\n",
    "    resample_image(base_img, img_file, img_processedname)\n",
    "    \n",
    "    os.remove(f\"{img_processedname}.vrt\") #Delete temp file\n",
    "    print(f\"finished resampling image: {img_processedname}\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Compute median image\n",
    "This section of the notebook is used to create a median image from all the aligned images. Note: this section should only need to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all co-registered images and stack them into a big xarray\n",
    "datasets = []\n",
    "date_list = []\n",
    "for index, row in img_df.iterrows():\n",
    "    img_name = row[\"product_name\"]\n",
    "    img_date = row['datestr']\n",
    "    img_file = outpath_aligned.joinpath(f\"{img_name}_aligned.tif\")\n",
    "    img_arr = rioxr.open_rasterio(img_file)\n",
    "    datasets.append(img_arr)\n",
    "    date_list.append(img_date)\n",
    "\n",
    "time_var = xr.Variable('time', date_list)\n",
    "combined_arr = xr.concat(datasets, dim=time_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the pixel and band-wise median from the stacked xarray\n",
    "median_arr = combined_arr.median(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs temporary median file \n",
    "temp_median_file = outpath_aligned.joinpath(\"median_temp.tif\")\n",
    "median_arr.rio.to_raster(raster_path=temp_median_file)\n",
    "\n",
    "#Compresses temp median file into final median file\n",
    "median_file = outpath_aligned.joinpath(\"median_image.tif\")\n",
    "cmd = f\"gdal_translate -a_nodata 0 -co compress=LZW {temp_median_file} {median_file}\"\n",
    "subprocess.check_output(cmd, shell=True)\n",
    "os.remove(temp_median_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Tophat filtering and detection\n",
    "This section of the notebook performs the tophat filtering and outputs the final vehicle detections. If Stage 1 and 2 have already been run, start here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_xarray(export_arr, ref_arr, xr_filename):\n",
    "    \"\"\"\n",
    "    Function used to convert a numpy array to an xarray and export it\n",
    "    \n",
    "    Params:\n",
    "    ---------------------\n",
    "    export_arr: numpy array\n",
    "        array to be exported\n",
    "    ref_arr: xarray data array\n",
    "        reference xarray to be used to set up the output\n",
    "    xr_filename: pathlib Path\n",
    "        filepath for the output file\n",
    "    \"\"\"\n",
    "\n",
    "    coords = {'x': ref_arr.coords['x'].to_numpy(), 'y': ref_arr.coords['y'].to_numpy()}\n",
    "    export_xr = xr.DataArray(export_arr, coords=coords, dims=('y', 'x'))\n",
    "\n",
    "    export_xr.rio.write_crs(4326, inplace=True)\n",
    "    export_xr.rio.to_raster(raster_path=xr_filename) \n",
    "\n",
    "def get_kernel(size):\n",
    "    \"\"\"\n",
    "    Function defines kernels for multi-directional tophat filtering based on specified kernel size.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    size: int\n",
    "        size for the tophat kernel. Options are 3, 5, and 7 currently.\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    kernel_dict: dict\n",
    "        dictionary with tophat kernels\n",
    "    \"\"\"\n",
    "    \n",
    "    if size == 3:\n",
    "        kernel_0 = np.array([[0,0,0],\n",
    "                             [1,1,1],\n",
    "                             [0,0,0]])\n",
    "        kernel_45 = np.array([[1,0,0],\n",
    "                              [0,1,0],\n",
    "                              [0,0,1]])\n",
    "        kernel_90 = np.array([[0,1,0],\n",
    "                              [0,1,0],\n",
    "                              [0,1,0]])\n",
    "        kernel_135 = np.array([[0,0,1],\n",
    "                               [0,1,0],\n",
    "                               [1,0,0]])\n",
    "    \n",
    "    if size == 5:\n",
    "        kernel_0 = np.array([[0,0,0,0,0],\n",
    "                             [0,0,0,0,0],\n",
    "                             [1,1,1,1,1],\n",
    "                             [0,0,0,0,0],\n",
    "                             [0,0,0,0,0]])\n",
    "        kernel_45 = np.array([[1,0,0,0,0],\n",
    "                              [0,1,0,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,0,1,0],\n",
    "                              [0,0,0,0,1]])\n",
    "        kernel_90 = np.array([[0,0,1,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,1,0,0]])\n",
    "        kernel_135 = np.array([[0,0,0,0,1],\n",
    "                               [0,0,0,1,0],\n",
    "                               [0,0,1,0,0],\n",
    "                               [0,1,0,0,0],\n",
    "                               [1,0,0,0,0]])\n",
    "    if size == 7:\n",
    "        kernel_0 = np.array([[0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [1,1,1,1,1,1,1],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0]])\n",
    "        kernel_45 = np.array([[1,0,0,0,0,0,0],\n",
    "                              [0,1,0,0,0,0,0],\n",
    "                              [0,0,1,0,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,0,1,0,0],\n",
    "                              [0,0,0,0,0,1,0],\n",
    "                              [0,0,0,0,0,0,1]])\n",
    "        kernel_90 = np.array([[0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0]])\n",
    "        kernel_135 = np.array([[0,0,0,0,0,0,1],\n",
    "                               [0,0,0,0,0,1,0],\n",
    "                               [0,0,0,0,1,0,0],\n",
    "                               [0,0,0,1,0,0,0],\n",
    "                               [0,0,1,0,0,0,0],\n",
    "                               [0,1,0,0,0,0,0],\n",
    "                               [1,0,0,0,0,0,0]])\n",
    "\n",
    "    kernel_dict = {'kernel_0': kernel_0, 'kernel_45': kernel_45, 'kernel_90': kernel_90, 'kernel_135': kernel_135}\n",
    "\n",
    "    return kernel_dict\n",
    "\n",
    "def calc_tophat_band(band_arr, kernel_size, tophat_type):\n",
    "    \"\"\"\n",
    "    Computes multiple tophat filters for a specific difference band (difference between target image\n",
    "    band and median image band). Returns the minimum tophat value from the multi-directional filtering.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    band_arr: xarray data array\n",
    "        array for the specified band\n",
    "    kernel_size: int\n",
    "        size of kernel to use for tophat filtering\n",
    "    tophat_type: str\n",
    "        type of tophat filter to use. Options are \"white\" and \"black\"\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    min_tophat: xarray data array\n",
    "        pixel-wise minimum of all tophat kernels\n",
    "    \"\"\"\n",
    "\n",
    "    kernel_dict = get_kernel(size=kernel_size)\n",
    "    \n",
    "    tophat_arrlist = []\n",
    "\n",
    "    for key, val in kernel_dict.items():\n",
    "        if tophat_type=='white':\n",
    "            tophat_arr = morphology.white_tophat(band_arr, footprint=val)\n",
    "        if tophat_type=='black':\n",
    "            tophat_arr = morphology.black_tophat(band_arr, footprint=val)\n",
    "        tophat_arrlist.append(tophat_arr)\n",
    "\n",
    "    tophat_combine = np.array(tophat_arrlist)\n",
    "    tophat_combine_coords = {'x': band_arr.coords['x'].to_numpy(), 'y': band_arr.coords['y'].to_numpy()}\n",
    "    tophat_combine_xr = xr.DataArray(tophat_combine, coords=tophat_combine_coords, dims=('band', 'y', 'x'))\n",
    "    min_tophat = tophat_combine_xr.min(dim='band')\n",
    "\n",
    "    return min_tophat\n",
    "\n",
    "def calc_diff(band_arr, med_arr, method):\n",
    "    \"\"\"\n",
    "    Computes difference between band array from target image and corresponding\n",
    "    band from median image. Two methods are possible: simple pixel differencing or the\n",
    "    structural similarity index (ssim). Note that ssim was tested briefly but is not the \n",
    "    operational method.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    band_arr: xarray data array\n",
    "        band array from target image\n",
    "    med_arr: xarray data array\n",
    "        band array from median image\n",
    "    method: str\n",
    "        Type of difference method to apply. Options are \"diff\" and \"ssim\"\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    diff_arr: numpy array\n",
    "        array of pixel differences between band_arr and med_arr\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'diff':\n",
    "        diff_arr = band_arr.to_numpy() - med_arr.to_numpy()\n",
    "    if method == 'ssim':\n",
    "        ssim_score, diff_arr = ssim(med_arr.to_numpy(), band_arr.to_numpy(), win_size=3, full=True)\n",
    "\n",
    "    return diff_arr\n",
    "\n",
    "def run_tophat_filter(img_arr, median_arr, band_subset, diff_method, kernel_size):\n",
    "    \"\"\"\n",
    "    Function to perform tophat filtering on an image. Iterates through image bands, computes\n",
    "    difference between the target image band and the median image band, and runs tophat filtering\n",
    "    function (runs both \"black\" and \"white\" tophat filters). Once tophat filtering has been completed\n",
    "    for all bands, the maximum of all of the individual tophat filters for all bands is computed for each\n",
    "    tophat filter type (black and white).\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    img_arr: xarray data array\n",
    "        xarray data array for the target image\n",
    "    median_arr: xarray data array\n",
    "        xarray data array for the median image\n",
    "    band_subset: str\n",
    "        subset of image bands to use. Options are \"allbands\" to use all 8 superdove bands, or \n",
    "        \"4band\" to use only the BGRN bands.\n",
    "    diff_method: str\n",
    "        Type of difference method to apply. Options are \"diff\" and \"ssim\"\n",
    "    kernel_size: int\n",
    "        size of kernel to use for tophat filtering\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    tophat_dict: dict\n",
    "        dictionary containing numpy arrays for the two final tophat filters for the target image (black and white)\n",
    "    \"\"\"\n",
    "\n",
    "    tophat_typelist=['black', 'white']\n",
    "    band_index_dict = {'allbands': [0,1,2,3,4,5,6,7], '4band': [1,3,5,7]}\n",
    "    band_indices = band_index_dict[band_subset]\n",
    "\n",
    "    tophat_dict = {}\n",
    "    for tophat_type in tophat_typelist:\n",
    "        tophat_minlist = []\n",
    "        for i in range(0, len(img_arr)):\n",
    "            if i not in band_indices:\n",
    "                continue\n",
    "            band_xr = img_arr[i]\n",
    "            diff_arr = calc_diff(band_xr, median_arr[i], diff_method)\n",
    "            diff_xr = xr.DataArray(diff_arr, coords=band_xr.coords, dims=band_xr.dims, attrs=band_xr.attrs)\n",
    "            band_tophat = calc_tophat_band(diff_xr, kernel_size, tophat_type)\n",
    "            tophat_minlist.append(band_tophat)\n",
    "\n",
    "        min_tophat_combine_xr = xr.concat(tophat_minlist, dim='band')\n",
    "        tophat_final = min_tophat_combine_xr.max(dim='band')\n",
    "        tophat_dict[tophat_type] = tophat_final\n",
    "        \n",
    "        # tophat_finalfile = outpath_workdir.joinpath(f\"{select_date}_{diff_method}_method_tophat_{tophat_type}_kernel_{kernel_size}_{band_subset}.tif\")\n",
    "        # tophat_final.rio.write_crs(4326, inplace=True)\n",
    "        # tophat_final.rio.to_raster(raster_path=tophat_finalfile) \n",
    "\n",
    "    return tophat_dict\n",
    "\n",
    "def combine_filters(tophat_white_arr, tophat_black_arr):\n",
    "    \"\"\"\n",
    "    Combine the black and white tophat filters for the target image into a single filter which is\n",
    "    the pixel-wise maximum of both.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    tophat_white_arr: numpy array\n",
    "        white tophat filter array\n",
    "    tophat_black_arr: numpy array\n",
    "        black tophat filter array\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    max_tophat: xarray data array\n",
    "        combined tophat filter array\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_tophat = xr.concat([tophat_white_arr, tophat_black_arr], dim='band')\n",
    "    max_tophat = combined_tophat.max(dim='band')\n",
    "    max_tophat.rio.write_crs(4326, inplace=True)\n",
    "\n",
    "    return max_tophat\n",
    "\n",
    "def clip_tophat(max_tophat, clip_geom):\n",
    "    \"\"\"\n",
    "    Clips tophat filter to road and parking area geometry\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    max_tophat: xarray data array\n",
    "        tophat filter array\n",
    "    clip_geom: geopandas geodataframe\n",
    "        geodataframe containing the clipping geometry\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    clipped: xarray data array\n",
    "        clipped tophat filter array\n",
    "    \"\"\"\n",
    "\n",
    "    clipped = max_tophat.rio.clip(clip_geom.geometry.values, clip_geom.crs)\n",
    "\n",
    "    return clipped\n",
    "\n",
    "def apply_threshold(max_tophat, threshold):\n",
    "    \"\"\"\n",
    "    Function to apply a threshold to a tophat filter array to create a boolean array.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    max_tophat: xarray data array\n",
    "        tophat filter array\n",
    "    threshold: float\n",
    "        threshold to apply to tophat array\n",
    "\n",
    "    Returns:\n",
    "    tophat_bool: numpy array\n",
    "        boolean tophat array\n",
    "    ---------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    tophat_bool = xr.where(max_tophat >= threshold, 1, 0)\n",
    "    tophat_bool = tophat_bool.astype(np.int8).to_numpy()\n",
    "    \n",
    "    return tophat_bool\n",
    "\n",
    "def sieve_bool_filter(tophat_bool, sieve_thresh):\n",
    "    \"\"\"\n",
    "    Apply sieving to boolean tophat array to filter out small objects.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    tophat_bool: numpy array\n",
    "        boolean tophat array\n",
    "    sieve_thresh: int\n",
    "        threshold to use for sieving. Objects smaller than the threshold are removed.\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    tophat_sieve: numpy array\n",
    "        sieved boolean tophat array\n",
    "    \"\"\"\n",
    "    \n",
    "    labelled = label(tophat_bool)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        tophat_sieve = morphology.remove_small_objects(labelled, min_size=sieve_thresh, connectivity=1)\n",
    "        \n",
    "    tophat_sieve = np.where(tophat_sieve > 0, 1, 0)\n",
    "    tophat_sieve = tophat_sieve.astype(np.int8)\n",
    "    \n",
    "    return tophat_sieve\n",
    "\n",
    "def threshold_tophat(clipped_tophat, min_thresh, sieve_thresh):\n",
    "    \"\"\"\n",
    "    Function to apply thresholding to the image tophat filters to create boolean detection arrays.\n",
    "    Initiallty uses the maximum value from the tophat array and iteratively reduces until it reaches \n",
    "    the specified minimum threshold value. After each iteration the results from the previous iteration \n",
    "    is subtracted from the current one, and sieving is applied to remove small objects. The sieved \n",
    "    filter array is then added together with the previous results to create a combined array.\n",
    "    \n",
    "    Note this iterative approach does not seem to add much value over just using the minimum value right \n",
    "    from the get-go, but does reduce the number of stray pixels and makes the detections possibly a bit more cohesive.\n",
    "    The iterative approach was implemented to adhere to the workflow outlined in Chen et al. 2021\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    clipped_tophat: xarray data array\n",
    "        clipped tophat filter array\n",
    "    min_thresh: float\n",
    "        minimum threshold value to use to create boolean vehicle detection array\n",
    "    sieve_thresh: int\n",
    "        minimum object size (in pixels). Objects smaller than the specified size are removed\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    final_bool: numpy array\n",
    "        boolean vehicle detection array\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    max_thresh = clipped_tophat.max()\n",
    "    current_thresh = max_thresh\n",
    "    thresh_multiplier = 0.9\n",
    "\n",
    "    if current_thresh < min_thresh:\n",
    "        print(f'Max tophat value less than the specified minimum threshold setting: max tophat val = {max_thresh}; min threshold = {min_thresh}')\n",
    "        raise KeyboardInterrupt\n",
    "\n",
    "    first_iter = True\n",
    "    while current_thresh >= min_thresh:\n",
    "        if first_iter:\n",
    "            tophat_bool = apply_threshold(clipped_tophat, current_thresh)\n",
    "            tophat_bool = sieve_bool_filter(tophat_bool, sieve_thresh)\n",
    "            previous_bool = np.copy(tophat_bool)\n",
    "            first_iter = False\n",
    "        else:\n",
    "            tophat_bool = apply_threshold(clipped_tophat, current_thresh)\n",
    "            tophat_bool = tophat_bool - previous_bool\n",
    "            tophat_bool = sieve_bool_filter(tophat_bool, sieve_thresh)\n",
    "            previous_bool = previous_bool + tophat_bool\n",
    "        \n",
    "        current_thresh = current_thresh * thresh_multiplier\n",
    "\n",
    "    if current_thresh < min_thresh:\n",
    "        current_thresh = min_thresh\n",
    "        tophat_bool = apply_threshold(clipped_tophat, current_thresh)\n",
    "        tophat_bool = tophat_bool - previous_bool\n",
    "        tophat_bool = sieve_bool_filter(tophat_bool, sieve_thresh)\n",
    "        previous_bool = previous_bool + tophat_bool\n",
    "\n",
    "    final_bool = np.copy(previous_bool)\n",
    "\n",
    "    return final_bool\n",
    "\n",
    "def calc_tdi(clipped_band, detection_arr):\n",
    "    \"\"\"\n",
    "    Calculates the Traffic Density Index (TDI) by dividing the number of vehicle detection pixels\n",
    "    by the total number of pixels within the road and parking lot geometry mask.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    clipped_band: xarray data array\n",
    "        band from target image clipped to road geometry\n",
    "    detection_arr: numpy array\n",
    "        boolean vehicle detection array\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    tdi: float\n",
    "        computed tdi value\n",
    "    \"\"\"\n",
    "\n",
    "    total_pixels = np.count_nonzero(clipped_band.to_numpy())\n",
    "    detection_pixels = np.count_nonzero(detection_arr)\n",
    "\n",
    "    tdi = (detection_pixels / total_pixels) * 100.0\n",
    "\n",
    "    return tdi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tophat filtering code execution begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in median image file\n",
    "median_file = outpath_aligned.joinpath(\"median_image.tif\")\n",
    "median_arr = rioxr.open_rasterio(median_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create output directory for the tophat rasters and boolean vehicle detection rasters\n",
    "tophat_outpath = outpath_workdir.joinpath(\"tophat_rasters\")\n",
    "tophat_outpath.mkdir(exist_ok=True)\n",
    "\n",
    "detection_outpath = outpath_workdir.joinpath(\"detection_rasters\")\n",
    "detection_outpath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To process a single image, set a date in the \"select_date\" variable. Otherwise leave it set to None to process all images\n",
    "select_date = None\n",
    "# select_date = \"2022-12-24\"\n",
    "\n",
    "#Read in road clipping geometry\n",
    "road_geom_gpd = gpd.read_file(road_geom_file)\n",
    "\n",
    "\n",
    "band_subset = 'allbands' #select subset of image bands or run all bands. Options are 'allbands' to use all bands, or '4band' to only process BGRN\n",
    "diff_method = 'diff' #Method for comparing image with median image. 'diff' uses simple pixel differences, while 'ssim' uses the structural similarity index\n",
    "kernel_size=7 #size of kernel to use for tophat filtering. Options are 3, 5, and 7\n",
    "sieve_thresh = 5 #sieve threshold for filtering boolean detection arrays. Groups of detection pixels smaller than the threshold are removed\n",
    "min_thresh=0.015 #minimum threshold used for vehicle detections from tophat filter array. Program will iteratively use smaller threshold values down to the value specified here.\n",
    "\n",
    "tdi_list = [] #list of TDI values. Each TDI value from each image is appended to this list\n",
    "\n",
    "#Iterate through all images in img_df and run vehicle detection and tdi calculation. If \"select_date\" variable set, will only process selected image\n",
    "for index, content in img_df.iterrows():\n",
    "\n",
    "    img_name = content[\"product_name\"]\n",
    "    img_date = content['datestr']\n",
    "\n",
    "    if select_date and img_date != select_date:\n",
    "        continue\n",
    "\n",
    "    print(f'Calculating TDI for image: {img_name}')\n",
    "\n",
    "    img_file = outpath_aligned.joinpath(f\"{img_name}_aligned.tif\")\n",
    "    img_arr = rioxr.open_rasterio(img_file)\n",
    "    \n",
    "    #Create tophat filters for target image\n",
    "    tophat_dict = run_tophat_filter(img_arr, median_arr, band_subset, diff_method, kernel_size)\n",
    "\n",
    "    #Combine white and black tophat filters and save to file\n",
    "    max_tophat = combine_filters(tophat_dict['white'], tophat_dict['black'])\n",
    "    # tophat_combined_fname = outpath_workdir.joinpath(f\"{img_name}_{diff_method}_method_kernel_{kernel_size}_tophat.tif\")\n",
    "    tophat_tempname = tophat_outpath.joinpath(f\"{img_name}_tophat_temp.tif\")\n",
    "    tophat_combined_fname = tophat_outpath.joinpath(f\"{img_name}_tophat_raster.tif\")\n",
    "    max_tophat.rio.write_crs(4326, inplace=True)\n",
    "    max_tophat.rio.to_raster(raster_path=tophat_tempname) \n",
    "    cmd = f\"gdal_translate -co compress=LZW {tophat_tempname} {tophat_combined_fname}\"\n",
    "    subprocess.check_output(cmd, shell=True)\n",
    "\n",
    "    #Clip tophat array to road geometry\n",
    "    clipped_tophat = clip_tophat(max_tophat, road_geom_gpd)\n",
    "    \n",
    "    #Create boolean vehicle detection arry from clipped tophat array\n",
    "    final_bool = threshold_tophat(clipped_tophat, min_thresh, sieve_thresh)\n",
    "\n",
    "    #Output boolean vehicle detection array\n",
    "    # final_bool_fname = outpath_workdir.joinpath(f\"{img_name}_{diff_method}_method_kernel_{kernel_size}_minthresh_{min_thresh}_sieve_{sieve_thresh}.tif\")\n",
    "    bool_tempname = detection_outpath.joinpath(f\"{img_name}_vehicle_detection_temp.tif\")\n",
    "    final_bool_fname = detection_outpath.joinpath(f\"{img_name}_vehicle_detection_raster.tif\")\n",
    "    export_xarray(final_bool, clipped_tophat, bool_tempname)\n",
    "    cmd = f\"gdal_translate -a_nodata 0 -co compress=LZW {bool_tempname} {final_bool_fname}\"\n",
    "    subprocess.check_output(cmd, shell=True)\n",
    "\n",
    "    #Calculate TDI\n",
    "    clipped_img_band = img_arr[1].rio.clip(road_geom_gpd.geometry.values, road_geom_gpd.crs)\n",
    "    tdi = calc_tdi(clipped_img_band, final_bool)\n",
    "    tdi_list.append(tdi)\n",
    "\n",
    "    os.remove(tophat_tempname)\n",
    "    os.remove(bool_tempname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputting TDI to a CSV file and creating chart. This is the end of the current process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdi_df = img_df.copy()\n",
    "\n",
    "tdi_df['tdi'] = tdi_list\n",
    "\n",
    "tdi_pickle = outpath_workdir.joinpath(\"TDI_DF_2022-01-01_to_2023-03-27.pkl\")\n",
    "tdi_df.to_pickle(tdi_pickle)\n",
    "\n",
    "tdi_csv_file = outpath_workdir.joinpath(\"TDI_DF_2022-01-01_to_2023-03-27.csv\")\n",
    "tdi_df.to_csv(tdi_csv_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdi_pickle = outpath_workdir.joinpath(\"TDI_DF_2022-01-01_to_2023-03-27.pkl\")\n",
    "# with open(tdi_pickle, \"rb\") as f:\n",
    "#     tdi_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdi_df.nsmallest(5, 'tdi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdi_df.nlargest(5, 'tdi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating TDI time series line chart\n",
    "\n",
    "tdi_fig = px.line(tdi_df, x='date', y='tdi', color_discrete_map={'tdi': 'red'})\n",
    "tdi_fig.update_traces(line_color='red', line_width=2)\n",
    "\n",
    "fignamestr = f\"TDI_Chart_2022-01-01_to_2023-03-27\"\n",
    "tdi_out_png = outpath_workdir.joinpath(f\"{fignamestr}.png\")\n",
    "tdi_out_html = outpath_workdir.joinpath(f\"{fignamestr}.html\")\n",
    "tdi_fig.write_image(tdi_out_png)\n",
    "tdi_fig.write_html(tdi_out_html)\n",
    "tdi_fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC TESTING AREA IGNORE FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_df = img_df.loc[img_df[\"datestr\"] == select_date].iloc[0]\n",
    "# img_name = select_df[\"product_name\"]\n",
    "# img_date = select_df['datestr']\n",
    "# img_file = outpath_aligned.joinpath(f\"{img_name}_aligned.tif\")\n",
    "# img_arr = rioxr.open_rasterio(img_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tophat_combined_fname = outpath_workdir.joinpath(f\"{select_date}_{diff_method}_method_kernel_{kernel_size}_combinedtophat.tif\")\n",
    "# max_tophat.rio.write_crs(4326, inplace=True)\n",
    "# max_tophat.rio.to_raster(raster_path=tophat_combined_fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_thresh = 0.01\n",
    "# sieve_thresh = 2\n",
    "# tophat_bool = threshold_filter(clipped_tophat, bool_thresh, sieve_thresh)\n",
    "# tophat_bool_fname = outpath_workdir.joinpath(f\"{select_date}_{diff_method}_method_kernel_{kernel_size}_boolthresh_{bool_thresh}_sieve_{sieve_thresh}_clipped.tif\")\n",
    "# export_xarray(tophat_bool, clipped_tophat, tophat_bool_fname)\n",
    "# tophat_bool.rio.write_crs(4326, inplace=True)\n",
    "# tophat_bool.rio.to_raster(raster_path=tophat_bool_fname) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiometric normalization test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING RAD NORMALIZATION\n",
    "# def create_rad_regmodel(band_arr, med_arr):\n",
    "#     diff_arr = np.abs(band_arr - med_arr)\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         percent_diff_arr = np.divide(diff_arr, med_arr) * 100.0\n",
    "\n",
    "#     percent_val = np.nanpercentile(percent_diff_arr, 25.0)\n",
    "#     low_diff_arr = np.where(percent_diff_arr > percent_val, np.nan, percent_diff_arr)\n",
    "\n",
    "#     band_arr_trunc = np.where(np.isnan(low_diff_arr), np.nan, band_arr)\n",
    "#     med_arr_trunc = np.where(np.isnan(low_diff_arr), np.nan, med_arr)\n",
    "\n",
    "#     x = med_arr_trunc.reshape((-1,1))\n",
    "#     y = band_arr_trunc.reshape((-1,1))\n",
    "#     x = x[~np.isnan(x)].reshape((-1,1))\n",
    "#     y = y[~np.isnan(y)].reshape((-1,1))\n",
    "\n",
    "#     x_ = PolynomialFeatures(degree=1, include_bias=False).fit_transform(x)\n",
    "#     model = LinearRegression().fit(x_, y)\n",
    "\n",
    "#     slope = round(float(model.coef_[0]), 5)\n",
    "#     intercept = round(float(model.intercept_[0]), 5)\n",
    "\n",
    "#     band_shape = band_arr.shape\n",
    "#     band_reshape = band_arr.reshape(-1,1)\n",
    "#     x_ = PolynomialFeatures(degree=1, include_bias=False).fit_transform(band_reshape)\n",
    "#     pred_flat = model.predict(x_)\n",
    "#     pred_arr = pred_flat.reshape(band_shape)\n",
    "\n",
    "#     return pred_arr\n",
    "#     # return slope, intercept\n",
    "#     # return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# band_indices = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# # df_list = []\n",
    "\n",
    "# for index, content in img_df.iterrows():\n",
    "#     if index != 91:\n",
    "#         continue\n",
    "    \n",
    "#     img_name = content[\"product_name\"]\n",
    "#     img_date = content['datestr']\n",
    "#     img_file = outpath_aligned.joinpath(f\"{img_name}_aligned.tif\")\n",
    "#     img_arr = rioxr.open_rasterio(img_file)\n",
    "\n",
    "#     # img_dict = {}\n",
    "#     # img_dict['img_name'] = img_name\n",
    "#     pred_arr_list = []\n",
    "#     for band_index in band_indices:\n",
    "#         band_arr = img_arr[band_index].to_numpy()\n",
    "#         med_arr = median_arr[band_index].to_numpy()\n",
    "\n",
    "#         pred_arr = create_rad_regmodel(band_arr, med_arr)\n",
    "\n",
    "#         pred_arr_list.append(pred_arr)\n",
    "\n",
    "#         # slope, intercept = create_rad_regmodel(band_arr, med_arr)\n",
    "\n",
    "#         # img_dict[f'b{band_index+1}_slope'] = slope\n",
    "#         # img_dict[f'b{band_index+1}_intercept'] = intercept\n",
    "\n",
    "#     # img_reg_df = pd.DataFrame(img_dict, index=[0], columns=['img_name', 'b1_slope', 'b2_slope', 'b3_slope', 'b4_slope', 'b5_slope', 'b6_slope', 'b7_slope', 'b8_slope', 'b1_intercept', 'b2_intercept', 'b3_intercept', 'b4_intercept', 'b5_intercept', 'b6_intercept', 'b7_intercept', 'b8_intercept'])\n",
    "#     # df_list.append(img_reg_df)\n",
    "\n",
    "#     radcor_arr = np.array(pred_arr_list)\n",
    "#     radcor_fname = outpath_workdir.joinpath(f\"{img_date}_radcor.tif\")\n",
    "    \n",
    "#     radcor_xr = xr.DataArray(radcor_arr, coords=img_arr.coords, dims=img_arr.dims)\n",
    "#     radcor_xr.rio.write_crs(4326, inplace=True)\n",
    "#     radcor_xr.rio.to_raster(raster_path=radcor_fname) \n",
    "\n",
    "# regression_df = pd.concat(df_list)\n",
    "# regression_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression_df['b2_slope'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression_df.iloc[91]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb-skywatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
