{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Density Index Notebook\n",
    "This notebook is used to preprocess PlanetScope imagery which was previously downloaded, and then detect potential vehicle pixels, as well as calculate a Traffic Density Index (TDI) for all images in the time series. \n",
    "<br> The following assumptions are made: <br>\n",
    "1. PlanetScope imagery has been previously downloaded from the Skywatch platform using the skywatch-api-notebook.\n",
    "2. The images are 8-band analytic products acquired from the SuperDove satellite platform only.\n",
    "3. A CSV file for the downloaded images was created during image download from the skywatch-api-notebook.\n",
    "4. A road and parking lot GIS polygon file has been created to mask the imagery down to only the relevant areas where vehicles may be assumed to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rioxr\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from skimage import morphology\n",
    "from skimage.measure import label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths and read in files for subsequent processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main input filepath. All other files and folders should be nested under this one (aside from the road geom file specified below)\n",
    "inpath = Path(\"../../data/tdi_demo_files\")\n",
    "inpath = inpath.resolve()\n",
    "\n",
    "#Geometry file for clipping tdi outputs\n",
    "road_geom_file = Path(\"../../data/processed/beitbridge_road_mask_v2.gpkg\")\n",
    "road_geom_file = road_geom_file.resolve()\n",
    "\n",
    "# Folder containing images downloaded using the skywatch-api-notebook\n",
    "# If images were downloaded in multiple batches, make sure all desired images are located\n",
    "# within the folder specified here (nested subdirectories are ok)\n",
    "img_path = inpath.joinpath(\"images\") \n",
    "\n",
    "outpath_aligned = inpath.joinpath(\"processed_images\") #Output path for co-aligned images\n",
    "outpath_aligned.mkdir(exist_ok=True)\n",
    "\n",
    "outpath_workdir = inpath.joinpath(\"tdi_outputs\") #Output directory for TDI file outputs\n",
    "outpath_workdir.mkdir(exist_ok=True)\n",
    "\n",
    "# Directory containing pickle files with image dataframes (generated during image download stage of skywatch-api-notebook\n",
    "# If images were downloaded in multiple stages (i.e. multiple date ranges), ensure pickle files for each set of downloads\n",
    "# are present in this folder.\n",
    "img_df_path = inpath.joinpath(\"download_dataframes\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in image dataframe(s). If multiple dataframes, put them all together into one.\n",
    "\n",
    "img_df_pickle_files = list(img_df_path.glob(\"*_download_df.pkl\"))\n",
    "\n",
    "if len(img_df_pickle_files) > 1:\n",
    "    img_df_list = []\n",
    "    for picklefile in img_df_pickle_files:\n",
    "        with open(picklefile, \"rb\") as f:\n",
    "            img_df_temp = pickle.load(f)\n",
    "        img_df_list.append(img_df_temp)\n",
    "\n",
    "    img_df = pd.concat(img_df_list)\n",
    "    img_df.sort_values(by=['date'], inplace=True)\n",
    "    img_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "else:\n",
    "    picklefile = img_df_pickle_files[0]\n",
    "    with open(picklefile, \"rb\") as f:\n",
    "        img_df = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Align images\n",
    "This section of the notebook is to take the PlanetScope images downloaded using the skywatch api notebook and resample them to a common pixel grid. <br>\n",
    "Note: this step should only need to be run one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all image files in image directory.\n",
    "image_files = list(img_path.rglob(\"*_analytic.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_im_file(image_files, img_name):\n",
    "    \"\"\"\n",
    "    Finds an image file in a list of file paths by matching an input image name.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    image_files: list\n",
    "        list of \n",
    "    img_name: str\n",
    "        base name of the image file\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    img_file: pathlib path object\n",
    "        file path of the image file\n",
    "    img_exists: bool\n",
    "        boolean variable stating whether the target file exists\n",
    "    \"\"\"\n",
    "    \n",
    "    im_name_flist = [im for im in image_files if img_name in str(im)]\n",
    "\n",
    "    if len(im_name_flist) == 1:\n",
    "        img_file = im_name_flist[0]\n",
    "        img_exists = True\n",
    "    elif len(im_name_flist) == 0:\n",
    "        img_file = \"\"\n",
    "        img_exists = False\n",
    "    \n",
    "    return img_file, img_exists\n",
    "\n",
    "def resample_image(base_img, warp_imgname, out_name):\n",
    "    \"\"\"\n",
    "    Function to resample an image to match the base image\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    base_img: rasterio dataset\n",
    "        base image to be aligned to\n",
    "    warp_imgname: pathlib Path\n",
    "        path to the image to be resampled.\n",
    "    out_name: pathlib Path\n",
    "        output path for resampled image\n",
    "    \"\"\"\n",
    "    \n",
    "    srs = base_img.crs.to_string()\n",
    "    pixelsize_x, pixelsize_y = base_img.res\n",
    "    bbox = base_img.bounds\n",
    "\n",
    "    #First step: create temp file using gdalwarp which resamples the target image to match the base image\n",
    "    cmd = f\"gdalwarp -t_srs {srs} -tap -tr {pixelsize_x} {pixelsize_y} -r near -te {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]} -te_srs {srs} -of vrt {warp_imgname} {out_name}.vrt -overwrite\"\n",
    "    subprocess.check_output(cmd, shell=True)\n",
    "\n",
    "    #Second step: use gdal_translate to compress the temp file into the final output\n",
    "    cmd2 = f\"gdal_translate -co compress=LZW {out_name}.vrt {out_name}.tif\"\n",
    "    subprocess.check_output(cmd2, shell=True)\n",
    "\n",
    "    os.remove(f\"{out_name}.vrt\") #Delete temp file\n",
    "\n",
    "#Set up a base image to resample everything to match. It selects the first image with 100% AOI coverage to use as the base image\n",
    "full_cover_img_df = img_df.loc[img_df[\"aoi_coverage\"] == 100]\n",
    "base_index = 0\n",
    "base_imgname = full_cover_img_df.iloc[base_index][\"product_name\"]\n",
    "base_img_file, base_img_exists = find_im_file(image_files, base_imgname)\n",
    "\n",
    "if not base_img_exists:\n",
    "    base_index += 1\n",
    "    while not base_img_exists:\n",
    "        base_imgname = full_cover_img_df.iloc[base_index][\"product_name\"]\n",
    "        base_img_file, base_img_exists = find_im_file(image_files, base_imgname)\n",
    "        base_index +=1\n",
    "\n",
    "base_img = rio.open(base_img_file)\n",
    "\n",
    "#Iterate through all the images in the img_df dataframe and resample to match the base image\n",
    "for index, row in img_df.iterrows():\n",
    "    img_name = row[\"product_name\"]    \n",
    "    img_file, img_exists = find_im_file(image_files, img_name)\n",
    "    if not img_exists:\n",
    "        print(f\"Warning: No file found for image: {img_name}. Skipping\")\n",
    "        continue\n",
    "    img_processedname = outpath_aligned.joinpath(f\"{img_name}_aligned\")\n",
    "    resample_image(base_img, img_file, img_processedname)\n",
    "    print(f\"finished resampling image: {img_processedname}\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Compute median image\n",
    "This section of the notebook is used to create a median image from all the aligned images. Note: this section should only need to be run one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through all co-registered images and stack them into a big xarray\n",
    "datasets = []\n",
    "date_list = []\n",
    "for index, row in img_df.iterrows():\n",
    "    img_name = row[\"product_name\"]\n",
    "    img_date = row['datestr']\n",
    "    img_file = outpath_aligned.joinpath(f\"{img_name}_aligned.tif\")\n",
    "    if not Path.exists(img_file):\n",
    "        print(f\"Warning: No file found for image: {img_name}. Skipping\")\n",
    "        continue\n",
    "    img_arr = rioxr.open_rasterio(img_file)\n",
    "    datasets.append(img_arr)\n",
    "    date_list.append(img_date)\n",
    "\n",
    "time_var = xr.Variable('time', date_list)\n",
    "combined_arr = xr.concat(datasets, dim=time_var)\n",
    "combined_arr = combined_arr.chunk({'time': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the pixel and band-wise median from the stacked xarray\n",
    "median_arr = combined_arr.median(dim='time').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs temporary median file \n",
    "temp_median_file = outpath_aligned.joinpath(\"median_temp.tif\")\n",
    "median_arr.rio.to_raster(raster_path=temp_median_file)\n",
    "\n",
    "#Compresses temp median file into final median file. Delete temp file\n",
    "median_file = outpath_aligned.joinpath(\"median_image.tif\")\n",
    "cmd = f\"gdal_translate -a_nodata 0 -co compress=LZW {temp_median_file} {median_file}\"\n",
    "subprocess.check_output(cmd, shell=True)\n",
    "os.remove(temp_median_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Tophat filtering, vehicle detection, & computing TDI\n",
    "This section of the notebook performs the tophat filtering and outputs the final vehicle detections. If Stage 1 and 2 have already been run, start here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_xarray(export_arr, ref_arr, xr_filename):\n",
    "    \"\"\"\n",
    "    Function used to convert a numpy array to an xarray and export it\n",
    "    \n",
    "    Params:\n",
    "    ---------------------\n",
    "    export_arr: numpy array\n",
    "        array to be exported\n",
    "    ref_arr: xarray data array\n",
    "        reference xarray to be used to set up the output\n",
    "    xr_filename: pathlib Path\n",
    "        filepath for the output file\n",
    "    \"\"\"\n",
    "\n",
    "    coords = {'x': ref_arr.coords['x'].to_numpy(), 'y': ref_arr.coords['y'].to_numpy()}\n",
    "    export_xr = xr.DataArray(export_arr, coords=coords, dims=('y', 'x'))\n",
    "\n",
    "    export_xr.rio.write_crs(4326, inplace=True)\n",
    "    export_xr.rio.to_raster(raster_path=xr_filename) \n",
    "\n",
    "def get_kernel(size):\n",
    "    \"\"\"\n",
    "    Function defines kernels for multi-directional tophat filtering based on specified kernel size.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    size: int\n",
    "        size for the tophat kernel. Options are 3, 5, and 7 currently.\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    kernel_dict: dict\n",
    "        dictionary with tophat kernels\n",
    "    \"\"\"\n",
    "    \n",
    "    if size == 3:\n",
    "        kernel_0 = np.array([[0,0,0],\n",
    "                             [1,1,1],\n",
    "                             [0,0,0]])\n",
    "        kernel_45 = np.array([[1,0,0],\n",
    "                              [0,1,0],\n",
    "                              [0,0,1]])\n",
    "        kernel_90 = np.array([[0,1,0],\n",
    "                              [0,1,0],\n",
    "                              [0,1,0]])\n",
    "        kernel_135 = np.array([[0,0,1],\n",
    "                               [0,1,0],\n",
    "                               [1,0,0]])\n",
    "    \n",
    "    if size == 5:\n",
    "        kernel_0 = np.array([[0,0,0,0,0],\n",
    "                             [0,0,0,0,0],\n",
    "                             [1,1,1,1,1],\n",
    "                             [0,0,0,0,0],\n",
    "                             [0,0,0,0,0]])\n",
    "        kernel_45 = np.array([[1,0,0,0,0],\n",
    "                              [0,1,0,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,0,1,0],\n",
    "                              [0,0,0,0,1]])\n",
    "        kernel_90 = np.array([[0,0,1,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,1,0,0],\n",
    "                              [0,0,1,0,0]])\n",
    "        kernel_135 = np.array([[0,0,0,0,1],\n",
    "                               [0,0,0,1,0],\n",
    "                               [0,0,1,0,0],\n",
    "                               [0,1,0,0,0],\n",
    "                               [1,0,0,0,0]])\n",
    "    if size == 7:\n",
    "        kernel_0 = np.array([[0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [1,1,1,1,1,1,1],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0]])\n",
    "        kernel_45 = np.array([[1,0,0,0,0,0,0],\n",
    "                              [0,1,0,0,0,0,0],\n",
    "                              [0,0,1,0,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,0,1,0,0],\n",
    "                              [0,0,0,0,0,1,0],\n",
    "                              [0,0,0,0,0,0,1]])\n",
    "        kernel_90 = np.array([[0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0],\n",
    "                              [0,0,0,1,0,0,0]])\n",
    "        kernel_135 = np.array([[0,0,0,0,0,0,1],\n",
    "                               [0,0,0,0,0,1,0],\n",
    "                               [0,0,0,0,1,0,0],\n",
    "                               [0,0,0,1,0,0,0],\n",
    "                               [0,0,1,0,0,0,0],\n",
    "                               [0,1,0,0,0,0,0],\n",
    "                               [1,0,0,0,0,0,0]])\n",
    "\n",
    "    kernel_dict = {'kernel_0': kernel_0, 'kernel_45': kernel_45, 'kernel_90': kernel_90, 'kernel_135': kernel_135}\n",
    "\n",
    "    return kernel_dict\n",
    "\n",
    "def calc_tophat_band(band_arr, kernel_size, tophat_type):\n",
    "    \"\"\"\n",
    "    Computes multiple tophat filters for a specific difference band (difference between target image\n",
    "    band and median image band). Returns the minimum tophat value from the multi-directional filtering.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    band_arr: xarray data array\n",
    "        array for the specified band\n",
    "    kernel_size: int\n",
    "        size of kernel to use for tophat filtering\n",
    "    tophat_type: str\n",
    "        type of tophat filter to use. Options are \"white\" and \"black\"\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    min_tophat: xarray data array\n",
    "        pixel-wise minimum of all tophat kernels\n",
    "    \"\"\"\n",
    "\n",
    "    #Get tophat filter kernels for specified kernel size\n",
    "    kernel_dict = get_kernel(size=kernel_size)\n",
    "    \n",
    "    tophat_arrlist = []\n",
    "\n",
    "    #Run selected tophat filter type for every tophat kernel on diff image. Append to list\n",
    "    for key, val in kernel_dict.items():\n",
    "        if tophat_type=='white':\n",
    "            tophat_arr = morphology.white_tophat(band_arr, footprint=val)\n",
    "        if tophat_type=='black':\n",
    "            tophat_arr = morphology.black_tophat(band_arr, footprint=val)\n",
    "        tophat_arrlist.append(tophat_arr)\n",
    "\n",
    "    #Create stacked tophat xarray from list of tophat filters\n",
    "    tophat_combine = np.array(tophat_arrlist)\n",
    "    tophat_combine_coords = {'x': band_arr.coords['x'].to_numpy(), 'y': band_arr.coords['y'].to_numpy()}\n",
    "    tophat_combine_xr = xr.DataArray(tophat_combine, coords=tophat_combine_coords, dims=('band', 'y', 'x'))\n",
    "    \n",
    "    #Compute pixel-wise minimum tophat value and return\n",
    "    min_tophat = tophat_combine_xr.min(dim='band')\n",
    "\n",
    "    return min_tophat\n",
    "\n",
    "def calc_diff(band_arr, med_arr):\n",
    "    \"\"\"\n",
    "    Computes difference between band array from target image and corresponding\n",
    "    band from median image.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    band_arr: xarray data array\n",
    "        band array from target image\n",
    "    med_arr: xarray data array\n",
    "        band array from median image\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    diff_arr: numpy array\n",
    "        array of pixel differences between band_arr and med_arr\n",
    "    \"\"\"\n",
    "\n",
    "    diff_arr = band_arr.to_numpy() - med_arr.to_numpy()\n",
    "\n",
    "    return diff_arr\n",
    "\n",
    "def run_tophat_filter(img_arr, median_arr, sat_type, band_subset, kernel_size):\n",
    "    \"\"\"\n",
    "    Function to perform tophat filtering on an image. Iterates through image bands, computes\n",
    "    difference between the target image band and the median image band, and runs tophat filtering\n",
    "    function (runs both \"black\" and \"white\" tophat filters). Once tophat filtering has been completed\n",
    "    for all bands, the maximum of all of the individual tophat filters for all bands is computed for each\n",
    "    tophat filter type (black and white).\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    img_arr: xarray data array\n",
    "        xarray data array for the target image\n",
    "    median_arr: xarray data array\n",
    "        xarray data array for the median image\n",
    "    sat_type: str\n",
    "        type of satellite that acquired the image\n",
    "    band_subset: str\n",
    "        subset of image bands to use for superdove. Options are \"allbands\" to use all 8 superdove \n",
    "        bands, or \"4band\" to use only the BGRN bands. If satellite type is not superdove, the 4\n",
    "        BGRN bands are used by default.\n",
    "    kernel_size: int\n",
    "        size of kernel to use for tophat filtering\n",
    "    \n",
    "    Returns:\n",
    "    ---------------------\n",
    "    tophat_dict: dict\n",
    "        dictionary containing numpy arrays for the two final tophat filters for the target image (black and white)\n",
    "    \"\"\"\n",
    "\n",
    "    tophat_typelist=['black', 'white']\n",
    "    band_index_dict = {'allbands': [0,1,2,3,4,5,6,7], '4band': [1,3,5,7]}\n",
    "\n",
    "    # If images are from super dove satellites, bands selected based on band_subset variable.\n",
    "    # For dove-classic and dove-r, all 4 BGRN bands are used.\n",
    "    if sat_type == 'superdove':\n",
    "        band_indices = band_index_dict[band_subset]\n",
    "    else: band_indices = [0,1,2,3]\n",
    "\n",
    "    tophat_dict = {}\n",
    "\n",
    "    #Iterate through image bands and run tophat filter processes for each tophat type (white and black)\n",
    "    #1. Create difference band\n",
    "    #2. Run multi-directional tophat filter function\n",
    "    #3. Calculate pixel-wise maximum tophat value from all bands\n",
    "    #4. Return dict containing max tophat bands for both white and black tophat filters\n",
    "    for tophat_type in tophat_typelist:\n",
    "        tophat_minlist = []\n",
    "        for i in range(0, len(img_arr)):\n",
    "            if i not in band_indices:\n",
    "                continue\n",
    "            band_xr = img_arr[i]\n",
    "            diff_arr = calc_diff(band_xr, median_arr[i])\n",
    "            diff_xr = xr.DataArray(diff_arr, coords=band_xr.coords, dims=band_xr.dims, attrs=band_xr.attrs)\n",
    "            band_tophat = calc_tophat_band(diff_xr, kernel_size, tophat_type)\n",
    "            tophat_minlist.append(band_tophat)\n",
    "\n",
    "        min_tophat_combine_xr = xr.concat(tophat_minlist, dim='band')\n",
    "        tophat_final = min_tophat_combine_xr.max(dim='band')\n",
    "        tophat_dict[tophat_type] = tophat_final\n",
    "\n",
    "    return tophat_dict\n",
    "\n",
    "def combine_filters(tophat_white_arr, tophat_black_arr):\n",
    "    \"\"\"\n",
    "    Combine the black and white tophat filters for the target image into a single filter which is\n",
    "    the pixel-wise maximum of both.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    tophat_white_arr: numpy array\n",
    "        white tophat filter array\n",
    "    tophat_black_arr: numpy array\n",
    "        black tophat filter array\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    max_tophat: xarray data array\n",
    "        combined tophat filter array\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_tophat = xr.concat([tophat_white_arr, tophat_black_arr], dim='band')\n",
    "    max_tophat = combined_tophat.max(dim='band')\n",
    "    max_tophat.rio.write_crs(4326, inplace=True)\n",
    "\n",
    "    return max_tophat\n",
    "\n",
    "def clip_tophat(max_tophat, clip_geom):\n",
    "    \"\"\"\n",
    "    Clips tophat filter to road and parking area geometry\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    max_tophat: xarray data array\n",
    "        tophat filter array\n",
    "    clip_geom: geopandas geodataframe\n",
    "        geodataframe containing the clipping geometry\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    clipped: xarray data array\n",
    "        clipped tophat filter array\n",
    "    \"\"\"\n",
    "\n",
    "    clipped = max_tophat.rio.clip(clip_geom.geometry.values, clip_geom.crs)\n",
    "\n",
    "    return clipped\n",
    "\n",
    "def apply_threshold(max_tophat, threshold):\n",
    "    \"\"\"\n",
    "    Function to apply a threshold to a tophat filter array to create a boolean array.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    max_tophat: xarray data array\n",
    "        tophat filter array\n",
    "    threshold: float\n",
    "        threshold to apply to tophat array\n",
    "\n",
    "    Returns:\n",
    "    tophat_bool: numpy array\n",
    "        boolean tophat array\n",
    "    ---------------------\n",
    "    \"\"\"\n",
    "    \n",
    "    tophat_bool = xr.where(max_tophat >= threshold, 1, 0)\n",
    "    tophat_bool = tophat_bool.astype(np.int8).to_numpy()\n",
    "    \n",
    "    return tophat_bool\n",
    "\n",
    "def sieve_bool_filter(tophat_bool, sieve_thresh):\n",
    "    \"\"\"\n",
    "    Apply sieving to boolean tophat array to filter out small objects.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    tophat_bool: numpy array\n",
    "        boolean tophat array\n",
    "    sieve_thresh: int\n",
    "        threshold to use for sieving. Objects smaller than the threshold are removed.\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    tophat_sieve: numpy array\n",
    "        sieved boolean tophat array\n",
    "    \"\"\"\n",
    "    \n",
    "    labelled = label(tophat_bool)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        tophat_sieve = morphology.remove_small_objects(labelled, min_size=sieve_thresh, connectivity=1)\n",
    "        \n",
    "    tophat_sieve = np.where(tophat_sieve > 0, 1, 0)\n",
    "    tophat_sieve = tophat_sieve.astype(np.int8)\n",
    "    \n",
    "    return tophat_sieve\n",
    "\n",
    "def threshold_tophat(clipped_tophat, min_thresh, sieve_thresh):\n",
    "    \"\"\"\n",
    "    Function to apply thresholding to the image tophat filters to create boolean detection arrays.\n",
    "    Initiallty uses the maximum value from the tophat array and iteratively reduces until it reaches \n",
    "    the specified minimum threshold value. After each iteration the results from the previous iteration \n",
    "    is subtracted from the current one, and sieving is applied to remove small objects. The sieved \n",
    "    filter array is then added together with the previous results to create a combined array.\n",
    "    \n",
    "    Note this iterative approach does not seem to add much value over just using the minimum value right \n",
    "    from the get-go, but does reduce the number of stray pixels and makes the detections possibly a bit more cohesive.\n",
    "    The iterative approach was implemented to adhere to the workflow outlined in Chen et al. 2021\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    clipped_tophat: xarray data array\n",
    "        clipped tophat filter array\n",
    "    min_thresh: float\n",
    "        minimum threshold value to use to create boolean vehicle detection array\n",
    "    sieve_thresh: int\n",
    "        minimum object size (in pixels). Objects smaller than the specified size are removed\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    final_bool: numpy array\n",
    "        boolean vehicle detection array\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    max_thresh = clipped_tophat.max()\n",
    "    current_thresh = max_thresh\n",
    "    thresh_multiplier = 0.9\n",
    "\n",
    "    if current_thresh < min_thresh:\n",
    "        print(f'Max tophat value less than the specified minimum threshold setting: max tophat val = {max_thresh}; min threshold = {min_thresh}')\n",
    "        raise KeyboardInterrupt\n",
    "\n",
    "    first_iter = True\n",
    "    while current_thresh >= min_thresh:\n",
    "        if first_iter:\n",
    "            tophat_bool = apply_threshold(clipped_tophat, current_thresh)\n",
    "            tophat_bool = sieve_bool_filter(tophat_bool, sieve_thresh)\n",
    "            previous_bool = np.copy(tophat_bool)\n",
    "            first_iter = False\n",
    "        else:\n",
    "            tophat_bool = apply_threshold(clipped_tophat, current_thresh)\n",
    "            tophat_bool = tophat_bool - previous_bool\n",
    "            tophat_bool = sieve_bool_filter(tophat_bool, sieve_thresh)\n",
    "            previous_bool = previous_bool + tophat_bool\n",
    "        \n",
    "        current_thresh = current_thresh * thresh_multiplier\n",
    "\n",
    "    if current_thresh < min_thresh:\n",
    "        current_thresh = min_thresh\n",
    "        tophat_bool = apply_threshold(clipped_tophat, current_thresh)\n",
    "        tophat_bool = tophat_bool - previous_bool\n",
    "        tophat_bool = sieve_bool_filter(tophat_bool, sieve_thresh)\n",
    "        previous_bool = previous_bool + tophat_bool\n",
    "\n",
    "    final_bool = np.copy(previous_bool)\n",
    "\n",
    "    return final_bool\n",
    "\n",
    "def calc_tdi(clipped_band, detection_arr):\n",
    "    \"\"\"\n",
    "    Calculates the Traffic Density Index (TDI) by dividing the number of vehicle detection pixels\n",
    "    by the total number of pixels within the road and parking lot geometry mask.\n",
    "\n",
    "    Params:\n",
    "    ---------------------\n",
    "    clipped_band: xarray data array\n",
    "        band from target image clipped to road geometry\n",
    "    detection_arr: numpy array\n",
    "        boolean vehicle detection array\n",
    "\n",
    "    Returns:\n",
    "    ---------------------\n",
    "    tdi: float\n",
    "        computed tdi value\n",
    "    \"\"\"\n",
    "\n",
    "    total_pixels = np.count_nonzero(clipped_band.to_numpy())\n",
    "    detection_pixels = np.count_nonzero(detection_arr)\n",
    "\n",
    "    tdi = (detection_pixels / total_pixels) * 100.0\n",
    "\n",
    "    return tdi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tophat filtering code execution begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the median image file\n",
    "median_file = outpath_aligned.joinpath(\"median_image.tif\")\n",
    "median_arr = rioxr.open_rasterio(median_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create output directory for the tophat rasters and boolean vehicle detection rasters\n",
    "tophat_outpath = outpath_workdir.joinpath(\"tophat_rasters\")\n",
    "tophat_outpath.mkdir(exist_ok=True)\n",
    "\n",
    "detection_outpath = outpath_workdir.joinpath(\"detection_rasters\")\n",
    "detection_outpath.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To process a single image, set a date in the \"select_date\" variable. Otherwise leave it set to None to process all images\n",
    "select_date = None\n",
    "# select_date = \"2022-12-24\"\n",
    "\n",
    "# Read in road clipping geometry\n",
    "road_geom_gpd = gpd.read_file(road_geom_file)\n",
    "\n",
    "\n",
    "band_subset = 'allbands' # Select subset of image bands or run all bands. Options are 'allbands' to use all bands, or '4band' to only process BGRN\n",
    "kernel_size=7 # Size of kernel to use for tophat filtering. Options are 3, 5, and 7. Larger kernels will detect larger pixel groupings.\n",
    "sieve_thresh = 5 # Sieve threshold for filtering boolean detection arrays. Groups of detection pixels smaller than the threshold are removed\n",
    "min_thresh=0.015 # Minimum threshold used for vehicle detections from tophat filter array. Program will iteratively use smaller threshold values down to the value specified here.\n",
    "\n",
    "tdi_list = [] # List of TDI values. Each TDI value from each image is appended to this list\n",
    "missing_imgs = [] # List of missing images. Used to filter final TDI dataframe.\n",
    "# Iterate through all images in img_df and run vehicle detection and tdi calculation. If \"select_date\" variable set, will only process selected image\n",
    "for index, content in img_df.iterrows():\n",
    "\n",
    "    img_name = content[\"product_name\"]\n",
    "    img_date = content['datestr']\n",
    "    sat_type = content['sat_type']\n",
    "\n",
    "    if select_date and img_date != select_date:\n",
    "        continue\n",
    "\n",
    "    print(f'Calculating TDI for image: {img_name}')\n",
    "\n",
    "    img_file = outpath_aligned.joinpath(f\"{img_name}_aligned.tif\")\n",
    "    if not Path.exists(img_file):\n",
    "        print(f\"Warning: No file found for image: {img_name}. Skipping\")\n",
    "        continue\n",
    "\n",
    "    img_arr = rioxr.open_rasterio(img_file)\n",
    "    \n",
    "    #Create tophat filters for target image\n",
    "    tophat_dict = run_tophat_filter(img_arr, median_arr, sat_type, band_subset, kernel_size)\n",
    "\n",
    "    #Combine white and black tophat filters and save to file\n",
    "    max_tophat = combine_filters(tophat_dict['white'], tophat_dict['black'])\n",
    "    tophat_tempname = tophat_outpath.joinpath(f\"{img_name}_tophat_temp.tif\")\n",
    "    tophat_combined_fname = tophat_outpath.joinpath(f\"{img_name}_tophat_raster.tif\")\n",
    "    max_tophat.rio.write_crs(4326, inplace=True)\n",
    "    max_tophat.rio.to_raster(raster_path=tophat_tempname) \n",
    "    cmd = f\"gdal_translate -co compress=LZW {tophat_tempname} {tophat_combined_fname}\"\n",
    "    subprocess.check_output(cmd, shell=True)\n",
    "\n",
    "    #Clip tophat array to road geometry\n",
    "    clipped_tophat = clip_tophat(max_tophat, road_geom_gpd)\n",
    "    \n",
    "    #Create boolean vehicle detection arry from clipped tophat array\n",
    "    final_bool = threshold_tophat(clipped_tophat, min_thresh, sieve_thresh)\n",
    "\n",
    "    #Output boolean vehicle detection array\n",
    "    bool_tempname = detection_outpath.joinpath(f\"{img_name}_vehicle_detection_temp.tif\")\n",
    "    final_bool_fname = detection_outpath.joinpath(f\"{img_name}_vehicle_detection_raster.tif\")\n",
    "    export_xarray(final_bool, clipped_tophat, bool_tempname)\n",
    "    cmd = f\"gdal_translate -a_nodata 0 -co compress=LZW {bool_tempname} {final_bool_fname}\"\n",
    "    subprocess.check_output(cmd, shell=True)\n",
    "\n",
    "    #Calculate TDI\n",
    "    clipped_img_band = img_arr[1].rio.clip(road_geom_gpd.geometry.values, road_geom_gpd.crs)\n",
    "    tdi = calc_tdi(clipped_img_band, final_bool)\n",
    "    tdi_list.append(tdi)\n",
    "\n",
    "    os.remove(tophat_tempname)\n",
    "    os.remove(bool_tempname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TDI dataframe and outputting to a CSV file and creating chart. This is the end of the current process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdi_df = img_df.copy()\n",
    "tdi_df['tdi'] = tdi_list\n",
    "\n",
    "tdi_csv_file = outpath_workdir.joinpath(\"TDI_DF_2022-01-01_to_2023-03-27.csv\")\n",
    "tdi_df.to_csv(tdi_csv_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating TDI time series line chart\n",
    "\n",
    "tdi_fig = px.line(tdi_df, x='date', y='tdi', color_discrete_map={'tdi': 'red'})\n",
    "tdi_fig.update_traces(line_color='red', line_width=2)\n",
    "\n",
    "fignamestr = f\"TDI_Chart_2022-01-01_to_2023-03-27\"\n",
    "tdi_out_png = outpath_workdir.joinpath(f\"{fignamestr}.png\")\n",
    "tdi_out_html = outpath_workdir.joinpath(f\"{fignamestr}.html\")\n",
    "tdi_fig.write_image(tdi_out_png)\n",
    "tdi_fig.write_html(tdi_out_html)\n",
    "tdi_fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb-skywatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
