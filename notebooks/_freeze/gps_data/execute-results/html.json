{
  "hash": "eecd38fd0c57a769b9449e059ff957d9",
  "result": {
    "markdown": "---\ntitle: \"Beitbridge Truck GPS Data\"\nauthor: \"Sparkgeo\"\ntoc: true\nformat:\n  html:\n    theme: zephyr\n    html-math-method: katex\n    code-tools: true\n    self-contained: true\n    embed-resources: true\n    link-external-icon: true\n    link-external-newwindow: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    df-print: kable\nexecute:\n  warning: false\n---\n\n\nThis notebook is cleaning the GPS data obtained by World Bank for future modelling and analysis.\n\n## Data Cleaning\n\n-   This notebook is for checking data quality on the GPS data\n\n-   Subsetting the data for our Study Period (2018-2022)\n\n-   Adding zeros and na values for completenesss since not every hour or every day is represented consistently in this data.\n\n## Load Libraries\n\n::: {.callout-note}\n\nWe'll be using `tidyverse` packages to read in and manipulate our data.\n\n-   `readr` is for reading in tabular data\n\n-   `skimr` provides a quick summary of tabular data\n\n-   `lubridate` is for working with date formats and time series\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(lubridate)\n```\n:::\n\n\n\nRead in the raw data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngps_data = read_csv(\"../data/raw/Beitbridge_Border_2017_02_01_to_2023_02_28.csv\")\n```\n:::\n\n\nRemove redundant field names and grand total from rest of table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#fix column names\ngps_data = gps_data %>%\n  rename_with(~ str_remove(., \"Border_Crossing_\"), everything())\n# remove grand total row\ngrand_total = gps_data[1,]\ngps_data =  gps_data[-1,]\n```\n:::\n\n\nWe can use skim to get a quick overview of the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskim(gps_data)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |         |\n|:------------------------|:--------|\n|Name                     |gps_data |\n|Number of rows           |68318    |\n|Number of columns        |10       |\n|_______________________  |         |\n|Column type frequency:   |         |\n|character                |2        |\n|logical                  |1        |\n|numeric                  |6        |\n|POSIXct                  |1        |\n|________________________ |         |\n|Group variables          |None     |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Direction     |         0|             1|  11|  12|     0|        4|          0|\n|GeozoneName   |         0|             1|  17|  17|     0|        1|          0|\n\n\n**Variable type: logical**\n\n|skim_variable        | n_missing| complete_rate| mean|count      |\n|:--------------------|---------:|-------------:|----:|:----------|\n|IsGrandTotalRowTotal |         0|             1|    0|FAL: 68318 |\n\n\n**Variable type: numeric**\n\n|skim_variable      | n_missing| complete_rate|    mean|      sd| p0|    p25|     p50|     p75|    p100|hist  |\n|:------------------|---------:|-------------:|-------:|-------:|--:|------:|-------:|-------:|-------:|:-----|\n|ProjectID          |         0|             1|    1.30|    0.71|  1|   1.00|    1.00|    1.00|     3.0|▇▁▁▁▂ |\n|StartHour          |         0|             1|   11.41|    5.96|  0|   7.00|   12.00|   16.00|    23.0|▅▇▆▇▅ |\n|Count_Events       |         0|             1|    3.17|    2.77|  1|   1.00|    2.00|    4.00|    52.0|▇▁▁▁▁ |\n|Median_Minutes     |         0|             1| 1523.23| 1773.96| 10| 335.00| 1029.37| 2096.00| 42633.0|▇▁▁▁▁ |\n|Bottom_10__Minutes |         0|             1| 1114.86| 1510.78| 10| 235.60|  634.70| 1394.60| 42633.0|▇▁▁▁▁ |\n|Top_10__Minutes    |         0|             1| 2227.06| 2460.80| 10| 497.02| 1416.00| 3074.45| 53702.6|▇▁▁▁▁ |\n\n\n**Variable type: POSIXct**\n\n|skim_variable | n_missing| complete_rate|min        |max        |median     | n_unique|\n|:-------------|---------:|-------------:|:----------|:----------|:----------|--------:|\n|StartDate     |         0|             1|2017-02-01 |2023-02-28 |2019-07-28 |     2210|\n:::\n:::\n\n\n## Cut the data for our Study Period\n\n-   Remove extra fields\n\n-   Format StartDate as date\n\n-   Replace spaces between Direction field for consistency\n\n-   Split our data set into two separate sets:\n\n    1.  `sa_zimbabwe` for those travelling in the SA --\\> Zimbabwe Direction\n    2.  `zimbabwe_sa` for those travelling Zimbabwe --\\> SA Direction\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngps_data = gps_data%>%\n  filter(between(year(StartDate), 2018, 2022))%>%\n  select(-c(IsGrandTotalRowTotal, GeozoneName, ProjectID))%>%\n  mutate(StartDate = as_date(StartDate),\n         Direction = str_replace_all(Direction,\" \",\"\"))\n\nsa_zimbabwe = gps_data %>%\n  filter(Direction == \"SA-Zimbabwe\")\n\nzimbabwe_sa = gps_data %>%\n  filter(Direction == \"Zimbabwe-SA\")\n```\n:::\n\n\n## Data Quality\n\n-   `Start_hour` - is not consistent need to add zeros to count events and other fields.\n\n-   Create a new `date_table` containing all of the dates and hours for our study period.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#YMD\n#Hours 0 to 23\n\nstart_date = ymd_hm(\"2018-01-01 00:00\")\nend_date = ymd_hm(\"2022-12-31 23:00\")\n\ndate_table = data.frame(StartDate = seq(start_date, end_date, by=\"hour\"))\n\ndate_table = date_table %>%\n  mutate(StartHour = hour(StartDate))%>%\n  mutate(StartDate = as_date(StartDate))\n```\n:::\n\n\n-   Join our gps data from each subset to our date table to fill in missing start hours and values with zero.\n\n-   Replace only Count_Events with zero and all `na` values applied to medians.\n\n-   We'll do this for both `sa_zimbabwe` and `zimbabwe_sa`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsa_zimbabwe = sa_zimbabwe %>%\n  full_join(date_table)%>%\n  mutate(Direction = \"SA-Zimbabwe\")%>%\n  mutate(across(c(Count_Events), ~replace_na(.x,0)))%>%\n  arrange(StartDate, StartHour)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nzimbabwe_sa = zimbabwe_sa %>%\n  full_join(date_table)%>%\n  mutate(Direction = \"Zimbabwe-SA\")%>%\n  mutate(across(c(Count_Events), ~replace_na(.x,0)))%>%\n  arrange(StartDate, StartHour)\n```\n:::\n\n\nPut it back together into one data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeitbridge_border = bind_rows(zimbabwe_sa, sa_zimbabwe)\n```\n:::\n\n\nSave the data to a new csv into our `processed` folder.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(beitbridge_border, \"../data/processed/Beitbridge_Counts_Wait_Time_2018_2022.csv\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}